---
title: "Replication of Twitter hate speech classification"
author: "Aboli Moroney, Mayank Goel, Samarth Modi, Harini Ramprasad"
knit: "bookdown::render_book"
output: html_document
# link-citations: yes
# colorlinks: yes
# lot: yes
# lof: yes
# fontsize: 12pt
# monofont: "Source Code Pro"
# monofontoptions: "Scale=0.7"
# site: bookdown::bookdown_site
# #description: "A guide to authoring books with R Markdown, including how to generate figures and tables, and insert "
# url: 'https\://bookdown.org/yihui/bookdown/'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::read_chunk('001-tweet-cleaning.R')
```

## Introduction

Lately, there has been a lot of effort and research on identifying content that is abusive or offensive on online and social media. Twitter recently published a relatively large and reliable dataset on ‘Hate and Abusive Speech on Twitter’. As Data Scientists, we fully understand the need to find the best methods and data for identifying such content and flagging it as inappropriate.
 
In this project, our aim is to reproduce some of the findings in a research paper that performs a comparative study and provides suggestions for using additional features and data for improving such classification of hate and abusive speech using Twitter data.

Using the data and code provided by the authors, we aim to replicate the efficacy and accuracy of machine learning models such as Naive Bayes, Logistic Regression, SVM and Random Forest presented in this paper. Our ultimate goal is to understand how each of these techniques performs on the different types of classifications and generate identical results for precision, recall and F1 score as reported by the authors. The choice of models to reproduce is based on the observation that the top precision has been generated by some of these models as well as our experimental constraints for executing the code.


## Data import and exploration

Importing the raw csv file. The csv file has about 30 columns. However, we would only need the following columns for our analyis.

1. tweet_id - unique identifier for each tweet 
2. tweet_text - raw tweet (uncleaned)
3. does_this_tweet_contain_hate_speech - (label with 3 different classes)


```{r Input-Data, echo=FALSE, results='hide', include=FALSE}
#Keeping only the necessary columns
#raw_data = raw_data[c("tweet_id", "tweet_text", "does_this_tweet_contain_hate_speech")]
#print(c("total number of tweets", dim(raw_data)[1]))
#head(raw_data)
data.frame(raw_data$does_this_tweet_contain_hate_speech)

```
## Tweet classification

Our output label columns consists of 3 different classes as following:

1. The tweet contains hate speech 
2. The tweet is not offensive
3. The tweet uses offensive language but not hate speech	

```{r}
# data.frame(summary(raw_data$does_this_tweet_contain_hate_speech))
```



## Data pre-processing

As a first step we would need to clean the tweet_text column.
This step involves

1. Converting all strings to lower case
2. Removing the punctuations
3. Removing the stopgap words

 To do so, we are using stringr package.



Here is the quick comparison between raw and cleaned tweets. 

```{r Data-Preparation}
data.frame(refined_data$tweet_text, refined_data$tweet_clean1)
```

In order to tokenize the tweets, we are using the 'quanteda' package.

```{r }

#To be fixed Tokenization
#data.frame(refined_data$tweet_text, refined_data$tweet_clean1)
```

## Natural Lanaguage Processing




## Results



